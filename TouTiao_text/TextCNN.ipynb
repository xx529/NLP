{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "TextCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bNzIh5DPXPe"
      },
      "source": [
        "# TextCNN\n",
        "1. 预训练词向量\n",
        "2. TextCNN网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM-33a4aPehC",
        "outputId": "e19fcc60-f9fb-4e82-c62f-1bb15441c0db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auMo0DkZcC6N"
      },
      "source": [
        "# Content Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4T-EovPn0c"
      },
      "source": [
        "import bz2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import jieba"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QC3BEBYej5I"
      },
      "source": [
        "## word vector\n",
        "\n",
        "从词向量预训练模型中建立词到向量映射"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3BTphVTPurd"
      },
      "source": [
        "with bz2.open('/content/drive/MyDrive/Colab Notebooks Project/NLP/TouTiao_text/sgns.weibo.word.bz2') as f:\n",
        "    info, *content = [x.decode('utf-8') for x in f.readlines()]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tenLOsX-agSp"
      },
      "source": [
        "word_to_vector = {}\n",
        "\n",
        "for ls in content:\n",
        "    word, *vector = ls.split()\n",
        "    word_to_vector[word] = np.array(vector).astype(np.float64)\n",
        "\n",
        "vector_dim = int(info.split()[1])\n",
        "word_to_vector['UNK'] = np.random.random(size=vector_dim)\n",
        "word_to_vector['PAD'] = np.random.random(size=vector_dim)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbYFW9C-e7_9"
      },
      "source": [
        "## training data\n",
        "\n",
        "1. 对训练数据的词转化成对应的id，如果预训练没有的词则统一变成‘UNK’标识 \n",
        "2. 对文本数据进行初步清洗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOY59RyIWbwV",
        "outputId": "1b3c3fbc-b959-4ae8-d882-7e8f5f74be3d"
      },
      "source": [
        "df_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks Project/NLP/TouTiao_text/train.csv')\n",
        "df_data['sentence_cut'] = df_data['sentence'].apply(jieba.lcut)\n",
        "df_data['label_for_train'] = pd.factorize(df_data['label'])[0]\n",
        "df_data.info()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53360 entries, 0 to 53359\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   id               53360 non-null  int64 \n",
            " 1   label            53360 non-null  int64 \n",
            " 2   label_desc       53360 non-null  object\n",
            " 3   sentence         53360 non-null  object\n",
            " 4   sentence_cut     53360 non-null  object\n",
            " 5   label_for_train  53360 non-null  int64 \n",
            "dtypes: int64(3), object(3)\n",
            "memory usage: 2.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPxADFMtXDDZ"
      },
      "source": [
        "word_to_id = {'UNK': 0, 'PAD': 1}\n",
        "id_to_word = {0: 'UNK', 1: 'PAD'}\n",
        "id_for_sentence = []\n",
        "\n",
        "id = 2\n",
        "for sentence in df_data['sentence_cut']:\n",
        "    id_list = []\n",
        "    for word in sentence:\n",
        "\n",
        "        if word not in word_to_vector:\n",
        "            id_list.append(word_to_id['UNK'])\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            if word not in word_to_id:\n",
        "                word_to_id[word] = id\n",
        "                id_to_word[id] = word\n",
        "                id += 1 \n",
        "\n",
        "            id_list.append(word_to_id[word])\n",
        "\n",
        "    id_for_sentence.append(id_list)\n",
        "\n",
        "df_data['id_for_sentence'] = id_for_sentence"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbpXq_NPZqKm",
        "outputId": "6e105606-e6b5-464b-d990-74459b09ad94"
      },
      "source": [
        "df_data['id_for_sentence']"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [2, 3, 4, 0, 5, 6, 7, 8, 9, 4, 10, 11, 6, 12, ...\n",
              "1        [0, 23, 24, 25, 26, 27, 28, 0, 29, 30, 31, 32,...\n",
              "2        [40, 41, 30, 42, 11, 43, 6, 44, 45, 46, 11, 6,...\n",
              "3                  [53, 32, 54, 55, 56, 57, 0, 58, 59, 22]\n",
              "4               [60, 34, 61, 62, 6, 0, 63, 64, 65, 66, 67]\n",
              "                               ...                        \n",
              "53355    [405, 447, 290, 0, 15918, 966, 81, 966, 13517,...\n",
              "53356        [1379, 4833, 158, 84, 36245, 40657, 34, 2967]\n",
              "53357    [44491, 848, 44492, 44493, 1264, 70, 11301, 75...\n",
              "53358    [116, 107, 590, 34, 485, 3955, 6, 9846, 899, 2...\n",
              "53359    [9619, 31951, 30867, 391, 6, 5303, 4172, 292, ...\n",
              "Name: id_for_sentence, Length: 53360, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FKuo6PHeDUY"
      },
      "source": [
        "## embedding matrix\n",
        "\n",
        "构建词向量的矩阵，矩阵对应行的行数就是词的向量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV9saA8Qf6xs"
      },
      "source": [
        "embedding_mat = np.zeros(shape=(len(word_to_id), vector_dim))\n",
        "\n",
        "for i in range(len(embedding_mat)):\n",
        "    embedding_mat[i] = word_to_vector[id_to_word[i]]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpyaHtVRZwd-"
      },
      "source": [
        "## padding & truncated\n",
        "\n",
        "让每个训练样本的序列长度一样"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jflz1LOHZ1BP"
      },
      "source": [
        "max_length = 20\n",
        "\n",
        "df_data['sentence_for_train'] = df_data['id_for_sentence'].apply(\n",
        "    lambda x: x+[1]*(max_length-len(x)) if max_length > len(x) else x[:max_length])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R0S4wnUlKEG"
      },
      "source": [
        "# TextCNN Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuy99MxT4sN8"
      },
      "source": [
        "## backbone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoDG-LH5lOrW",
        "outputId": "3b95afd0-df42-46c1-802c-c49b2c9954f8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, seq_length, emb_size, emb_dim, n_filter, filter_height, n_class):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(emb_size, emb_dim)\n",
        "        self.conv = nn.Conv2d(1, n_filter, (filter_height, emb_dim))\n",
        "        self.pool = nn.MaxPool1d(seq_length-filter_height+1)\n",
        "        self.fc = nn.Linear(n_filter, n_class)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).unsqueeze(1)\n",
        "        x = self.conv(x).squeeze(3)\n",
        "        x = self.pool(x).squeeze(2)\n",
        "        x = self.fc(x)\n",
        "        out = self.softmax(x)\n",
        "        return out\n",
        "\n",
        "model = TextCNN(10, 20, 7, 3, 4, 3)\n",
        "seq = torch.LongTensor(np.random.randint(0, 20, (12,10)))\n",
        "model(seq)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2797, 0.5482, 0.1720],\n",
              "        [0.4052, 0.4048, 0.1900],\n",
              "        [0.4263, 0.4593, 0.1143],\n",
              "        [0.2444, 0.6139, 0.1418],\n",
              "        [0.3495, 0.5728, 0.0777],\n",
              "        [0.3189, 0.5653, 0.1158],\n",
              "        [0.4794, 0.3682, 0.1525],\n",
              "        [0.5056, 0.4129, 0.0815],\n",
              "        [0.4531, 0.4562, 0.0907],\n",
              "        [0.5102, 0.3759, 0.1139],\n",
              "        [0.5259, 0.3003, 0.1738],\n",
              "        [0.2888, 0.5922, 0.1190]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAbM6HLe4u0h"
      },
      "source": [
        "## trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBUTkwz953yF"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class TrainModel(pl.LightningModule):\n",
        "    def __init__(self, ):\n",
        "        super(TrainModel, self).__init__()\n",
        "        self.backbone = \n",
        "        self.loss = \n",
        "\tself.lr = \n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self.backbone(x)\n",
        "        loss = self.loss(output, y)\n",
        "        self.log('Training Loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self.backbone(x)\n",
        "        loss = self.loss(output, y)\n",
        "        self.log('Validation Loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, x):\n",
        "\t\tpredict = self.backbone(x)\n",
        "\t\treturn predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2MItYMr5BhC"
      },
      "source": [
        "## dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9JLVyUR5CBB"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_tensor = torch.LongTensor(np.random.randint(0, 100, (500,8)))\n",
        "y_tensor = torch.LongTensor(np.random.randint(0, 3, (500)))\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_tensor, y_tensor)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=128, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(TensorDataset(x_valid, y_valid), batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTqX7FW_2TU-"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nfBbahj5zEi"
      },
      "source": [
        "model = TrainModel()\n",
        "trainer = pl.Trainer(max_epochs=50, logger=tb_logger, gpus=1, callbacks=[checkpoint_callback])\n",
        "trainer.fit(model, train_loader, valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}