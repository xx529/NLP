{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "TextCNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bNzIh5DPXPe"
      },
      "source": [
        "# TextCNN\n",
        "1. 预训练词向量\n",
        "2. TextCNN网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM-33a4aPehC",
        "outputId": "9b428689-23f2-4021-de89-cafaccf0f78d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auMo0DkZcC6N"
      },
      "source": [
        "# Content Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4T-EovPn0c"
      },
      "source": [
        "import bz2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import jieba"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QC3BEBYej5I"
      },
      "source": [
        "## word vector\n",
        "\n",
        "从词向量预训练模型中建立词到向量映射"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3BTphVTPurd"
      },
      "source": [
        "with bz2.open('/content/drive/MyDrive/Colab Notebooks Project/NLP/TouTiao_text/sgns.weibo.word.bz2') as f:\n",
        "    info, *content = [x.decode('utf-8') for x in f.readlines()]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tenLOsX-agSp"
      },
      "source": [
        "word_to_vector = {}\n",
        "\n",
        "for ls in content:\n",
        "    word, *vector = ls.split()\n",
        "    word_to_vector[word] = np.array(vector).astype(np.float64)\n",
        "\n",
        "vector_dim = int(info.split()[1])\n",
        "word_to_vector['UNK'] = np.random.random(size=vector_dim)\n",
        "word_to_vector['PAD'] = np.random.random(size=vector_dim)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbYFW9C-e7_9"
      },
      "source": [
        "## training data\n",
        "\n",
        "1. 对训练数据的词转化成对应的id，如果预训练没有的词则统一变成‘UNK’标识 \n",
        "2. 对文本数据进行初步清洗"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOY59RyIWbwV",
        "outputId": "0571a8ea-4eb0-4f4d-b19d-13ecfcce1946"
      },
      "source": [
        "df_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks Project/NLP/TouTiao_text/train.csv')\n",
        "df_data['sentence_cut'] = df_data['sentence'].apply(jieba.lcut)\n",
        "df_data.info()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53360 entries, 0 to 53359\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            53360 non-null  int64 \n",
            " 1   label         53360 non-null  int64 \n",
            " 2   label_desc    53360 non-null  object\n",
            " 3   sentence      53360 non-null  object\n",
            " 4   sentence_cut  53360 non-null  object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 2.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPxADFMtXDDZ"
      },
      "source": [
        "word_to_id = {'UNK': 0, 'PAD': 1}\n",
        "id_to_word = {0: 'UNK', 1: 'PAD'}\n",
        "id_for_sentence = []\n",
        "\n",
        "id = 2\n",
        "for sentence in df_data['sentence_cut']:\n",
        "    id_list = []\n",
        "    for word in sentence:\n",
        "\n",
        "        if word not in word_to_vector:\n",
        "            id_list.append(word_to_id['UNK'])\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            if word not in word_to_id:\n",
        "                word_to_id[word] = id\n",
        "                id_to_word[id] = word\n",
        "                id += 1 \n",
        "\n",
        "            id_list.append(word_to_id[word])\n",
        "\n",
        "    id_for_sentence.append(id_list)\n",
        "\n",
        "df_data['id_for_sentence'] = id_for_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbpXq_NPZqKm",
        "outputId": "f1a1be81-a9d1-4f8d-fbf8-0a3bcb30ed4d"
      },
      "source": [
        "df_data['id_for_sentence']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [2, 3, 4, 0, 5, 6, 7, 8, 9, 4, 10, 11, 6, 12, ...\n",
              "1        [0, 23, 24, 25, 26, 27, 28, 0, 29, 30, 31, 32,...\n",
              "2        [40, 41, 30, 42, 11, 43, 6, 44, 45, 46, 11, 6,...\n",
              "3                  [53, 32, 54, 55, 56, 57, 0, 58, 59, 22]\n",
              "4               [60, 34, 61, 62, 6, 0, 63, 64, 65, 66, 67]\n",
              "                               ...                        \n",
              "53355    [405, 447, 290, 0, 15918, 966, 81, 966, 13517,...\n",
              "53356        [1379, 4833, 158, 84, 36245, 40657, 34, 2967]\n",
              "53357    [44491, 848, 44492, 44493, 1264, 70, 11301, 75...\n",
              "53358    [116, 107, 590, 34, 485, 3955, 6, 9846, 899, 2...\n",
              "53359    [9619, 31951, 30867, 391, 6, 5303, 4172, 292, ...\n",
              "Name: id_for_sentence, Length: 53360, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FKuo6PHeDUY"
      },
      "source": [
        "## embedding matrix\n",
        "\n",
        "构建词向量的矩阵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV9saA8Qf6xs"
      },
      "source": [
        "embedding_mat = np.zeros(shape=(len(word_to_id), vector_dim))\n",
        "\n",
        "for i in range(len(embedding_mat)):\n",
        "    embedding_mat[i] = word_to_vector[id_to_word[i]]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pve6s__pT8ND",
        "outputId": "be0fbad2-41ee-4dfc-ed6c-0e77a07460d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding_mat.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44495, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIICdhDqVJIj",
        "outputId": "04767305-f9c2-410a-b0e9-55782735a510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_to_vector"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T21GsV83WR63",
        "outputId": "9e06e6b9-ae6a-4f21-a7c0-4b9c5be5754f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_to_vector['大家'] == embedding_mat[17]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}